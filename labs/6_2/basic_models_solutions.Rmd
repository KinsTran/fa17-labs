---
title: "Running Basic Models"
output: html_notebook
---

Loading data
```{r}
library(ggplot2)
library(dplyr)
require(broom)
load("data_sim1.Rda")
data_sim1
```

# Basic fitting of a model using R
Let's start by fitting a linear model using the built in package.

```{r}

#fit a linear model for y using x
linear_model <- lm (y ~ x, data = data_sim1)


# get the coefficients from the model
# tidy is a trick to make the model object from lm into a data frame
#   makes it easier to extract parts of it
#   -> you can access them with paramters[1] to get the intercept, [2] for the slope
parameters = tidy(linear_model)$estimate

#calculate the predictions from the lm model and add them to the data_sim1
#
data_sim1 <- data_sim1 %>%
  mutate(
    linear_model_prediction = parameters[1] + parameters[2] * data_sim1$x
  )

head(data_sim1)

#let's plot the data and the prediction
# hint: make the first layer have the predictions with larger sized points
#     so the actual data can be put on top of it 
ggplot(data_sim1 , aes(x)) +
  geom_point(aes(y= y), size = 3, colour = "red") +
  geom_line(aes(y= linear_model_prediction), size = 2, colour = "grey30")

```
Do you think this is a good model for the data set? Why?

What information would help you answer the question above better?

# Using different objective function for model fitting

For linear models, usually the objective function looks at the residuals (difference from prediction to actual value from the data). 
```{r}
model_linear_function <- function(a, data) {
  a[1] + data$x * a[2]
}

# example usage to make predictions
# model_linear_function(c(7,5), data_sim1)

model_function = model_linear_function
measure_distance <- function(mod_params, data) {
  diff <- data$y - model_function(mod_params, data)
  sqrt(mean(diff ^ 2))
}

# Here's a line fit with the objective function that lm uses - squares of the residuals
best <- optim(c(0, 0), measure_distance, data = data_sim1)


# values for the coefficients
best$par

# compare to coefficients of lm()
parameters
```
Are the parameter values the same from the two model fitting programs - using lm vs. using optim?

Now we'll use a different objective function - the absolute (not squared) distance.

```{r}
measure_distance_mad <- function(mod_params, data) {
  diff <- data$y - model_function(mod_params, data)
   mean(abs(diff))
}

# make use of a different distance function here (such as mean absolute)
mad_fit <- optim(c(0, 0), measure_distance_mad, data = data_sim1)
mad_fit$par


# put these in variables for more clarity
mad_fit_intercept = mad_fit$par[1]
mad_fit_slope = mad_fit$par[2]

#calculate the predictions from your line fit with MAD and add them to the data_sim1
# You can add predictions with mutate with any model, so this will work
#   for any type of model.
# See your code for the lm model to start from.
data_sim1 <- data_sim1 %>%
  mutate(
    lm_mad = mad_fit_intercept + mad_fit_slope * data_sim1$x
  )

# Now we plot the results with the empirical predictions for the MAD line
# See your code for the lm model 

ggplot(data=data_sim1, aes(x)) + 
  geom_point(aes(y=y), size = 3) +
  geom_line(aes(y=lm_mad), color = "gray30", size = 1) + 
  geom_line(aes(y=linear_model_prediction), color = "blue", size = 1)

# MAD is less sensitive to outliers
```

# Visualizing Residuals

Residuals are the difference between the outcome and the predicted outcome.

Answer these questions together after making plots to compare the residuals:
1) How do the residuals differ between the two models?
2) Why are they different?

```{r}
data_sim1
# add the residuals to the data set, one variable for each model you have
data_sim1 <- data_sim1 %>% 
 mutate(
     residuals_mad = y - lm_mad,
     residuals = y - linear_model_prediction
 )


# plot the residuals to compare them
ggplot(data_sim1, aes(x)) +
  geom_point(aes(y=residuals)) + 
  geom_point(aes(y=residuals_mad), color = "red") +
  geom_abline(intercept=0, slope = 0)

```


