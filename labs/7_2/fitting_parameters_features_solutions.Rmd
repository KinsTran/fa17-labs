---
title: "Fitting model parameters & features"
output: html_notebook
---

# Fitting model parameters & features
The objective of this lab is to have you practice fitting a model parameters and predictor variables.

You will apply what we have learned in class. Reference code from class and from the readings may be helpful. - (Class 7.1 Code on Cross Validation, Feature Selection)[https://github.com/info370/fa17-labs/tree/master/class/7.1]
- (Reading on Cross-Validation)[https://docs.google.com/document/d/1uNbgjp9CrxxwDrgLEDrf4IkJrUwZKO5TqxblWwRZkko/edit]
- (Slides on Cross-Validation, Feature Selection)[https://docs.google.com/presentation/d/1znngaVSsDb-ueXCPjdwPhdCEbjuged2J37Q69w0T2_M/edit?usp=sharing]


```{r setup}
if(!require(mlbench)){install.packages("mlbench"); require(mlbench)} # common datasets to use
if(!require(caret)){install.packages("caret", dependencies = c("Depends", "Suggests")); require(caret)} # ML package and its dependencies. This will take awhile!
if(!require(dplyr)){install.packages("dplyr"); require(dplyr)}
set.seed(370)
```

## 1. Look at the data
```{r}
data(BostonHousing)
?BostonHousing

df_boston <- BostonHousing[, !names(BostonHousing) %in% c("chas")] # removing charles river tract b/c not numeric
head(df_boston)
```

# Feature Selection

## 2. Correlation of Features
*TODO*: Create a correlation matrix and determine if any features are highly correalted
```{r}
corr_matrix <- cor(df_boston[,1:12]) # correlations between all predictor vars
corr_matrix

cutoff <- 0.6 # should be higher in practice

highly_corr <- findCorrelation(corr_matrix, cutoff=cutoff)
print(colnames(df_boston)[highly_corr]) # age is highly correalted with pregnant
```
*TODO*: Determine if which features are highly correlated

## Ranking features by importance
*TODO*: Rank features by importance using K-Nearest Neighbors (KNN). Plot the performance
- Use a k-fold cross-validation ("repeatedcv") with k=5 folds, repeated 3 times for control.
```{r}
control <- trainControl(method="repeatedcv", number = 10, repeats = 3)

model <- train(medv ~., data=df_boston, method = "knn", trControl = control)

importance <- varImp(model)

ggplot(importance)
```

## Automatic Feature Selection
*TODO* Use and `rfe` to do automatic feature selection. You'll want to pass in the control provided.
```{r}
# control using random forest
control <- rfeControl(functions = rfFuncs, method="cv", number=10)
results <- rfe(df_boston[,1:12], df_boston[,13], sizes = c(1:12), rfeControl = control) # this will take AWHILE...

results
ggplot(results)

# chosen features
predictors(results)
```

*TODO*: Select the most important features (up to 10) and use only those parameters moving forward
```{r}
selected_features <- predictors(results)[1:6] #TODO
selected_features
```


# Fitting parameters
Now it's time to try fitting different models. See more about models here: http://topepo.github.io/caret/available-models.html

*TODO*: Fit a generalized linear model
- Use `expand.grid()` to create a dataframe from all combinations of alpha (start with c(0, 0.1, 0.2, 0.4, 0.6, 0.8, 1.0) and adjust accordingrtly) and lambda values 1e-5, 1e-4, ... 1
```{r}
glmnet_grid <- expand.grid(alpha = c(0,  .1,  .2, .4, .6, .8, 1),
                           lambda = c(1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1,1))
glmnet_ctrl <- trainControl(method = "cv", number = 10)
glmnet_fit <- train(medv ~ ., data = df_boston[, c(selected_features, "medv")],
                    method = "glmnet",
                    preProcess = c("center", "scale"),
                    tuneGrid = glmnet_grid,
                    trControl = glmnet_ctrl)
glmnet_fit
```

*TODO*: Fit a penalized logistic regression model (plr) with all features (not just the ones we previously selected) to predict if a neighborhood is charles river tract or not (chas).

This model is problematic because the optimal lambda function is the largest one. Not sure what's happening here...
```{r}
df_boston_all <- BostonHousing
 
plr_grid <- expand.grid(lambda = c(1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1,1, 1e2, 1e3, 1e4, 1e5), cp = c("bic", "aic"))
plr_ctrl <- trainControl(method = "cv", number = 10)
plr_fit <- train(chas ~ ., data = df_boston_all,
                    method = "plr",
                    preProcess = c("center", "scale"),
                    tuneGrid = plr_grid,
                    trControl = plr_ctrl)
plr_fit
```

